{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42944ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish environment\n",
    "!pip3 install -r requirements.txt\n",
    "!pip3 install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01969f91",
   "metadata": {},
   "source": [
    "**由原始数据生成实验所用.arrow数据集。**\n",
    "\n",
    "参数：\n",
    "1. root: 原始数据所在文件夹\n",
    "2. arrows_root：所生成的数据所在文件夹，被模型读取\n",
    "3. days_per_period：将被整合成一个数据点（时期）的销量天数, n_periods：每个sku所取的period数\n",
    "4. debug：若为True，截取一部分sale数据进行快速测试\n",
    "\n",
    "所需原始数据:\n",
    "\n",
    "1. {root}/new_picture\n",
    "2. {root}/new_sale.csv\n",
    "3. {root}/new_attr.csv\n",
    "4. {root}/new_title.csv\n",
    "5. {root}/split_by_item.csv\n",
    "6. {root}/jieba_dict.txt\n",
    "\n",
    "**_Notes: 其中1-2文件过大需要自己上传，3-6通过coding平台同步。_**\n",
    "\n",
    "运行成功后，会生成如下文件：\n",
    "1. {arrows_root}/label_encoding.json\n",
    "2. {arrows_root}/word_decoding.json\n",
    "3. {arrows_root}/new_attr_cols.json\n",
    "4. {arrows_root}/*.arrow\n",
    "5. {arrows_root}/*.csv\n",
    "\n",
    "\n",
    "**_Notes: 1为属性和类别编码的对应关系；2为词与词编码的对应关系；3为MMP模型所读配置文件；4为MMP模型可读数据集；5为树模型可读数据集（不包含图片文本信息）。_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5892c53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/arrows/jd_t-shirt_14_5\n",
      "read 4454693 attr records with 6 cols\n",
      "trunc series with large std... before: 4454693\n",
      "after: 4291965\n",
      "remain 46208 valid skus with full history\n",
      "remain skus: 46208, records: 231040\n",
      "read 12 non-sequential attrs.\n",
      "remain 230090 records after merging non-sequential attrs\n",
      "no nan data detected.\n",
      "type invalid: split, object, may cause error when making arrows\n",
      "columns in structured data: ['item_sku_id', 'on_shelf_periods', 'sale_qtty', 'sale_ord_dt', 'jd_prc', 'year_no', 'month_no', 'week_no', 'day_no', 'material', 'style', 'barndname_full', 'pattern', 'edition', 'thickness', 'season', 'popularelements', 'size', 'people', 'sleeve', 'collar', 'dummy', 'item_id', 'split']\n",
      "reading text and image data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing text data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.914 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary: 1952\n",
      "read 50000 text-image records\n",
      "making csv for val datasets without text-image information...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing val attrs: 33730 valid records with maxlen=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6746/6746 [00:06<00:00, 991.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making arrow for val datasets: 6746 skus\n",
      "making csv for test datasets without text-image information...\n",
      "preparing test attrs: 35050 valid records with maxlen=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7010/7010 [00:06<00:00, 1044.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making arrow for test datasets: 7010 skus\n",
      "making csv for train datasets without text-image information...\n",
      "preparing train attrs: 161200 valid records with maxlen=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32240/32240 [00:31<00:00, 1023.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making arrow for train datasets: 32240 skus\n",
      "intersection of skus in val and test: 0\n",
      "intersection of skus in val and train: 0\n",
      "intersection of skus in test and train: 0\n",
      "make arrow successfully\n",
      "write attr cols file successfully!\n"
     ]
    }
   ],
   "source": [
    "# make data arrow\n",
    "import numpy \n",
    "from vilt.utils.write_jd_new import make_arrow\n",
    "from vilt.utils.write_attr_cols import write_new_attr_cols\n",
    "\n",
    "dataset = 'jd_t-shirt'\n",
    "days_per_period = 14\n",
    "n_periods = 5\n",
    "\n",
    "root = f'data/{dataset}'\n",
    "arrows_root = f'data/arrows/{dataset}_{days_per_period}_{n_periods}'\n",
    "\n",
    "print(arrows_root)\n",
    "make_arrow(root, arrows_root, days_per_period=days_per_period, n_periods=n_periods, debug=False, with_ti_embedding=False, trunc_sales=False)\n",
    "write_new_attr_cols(arrows_root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
